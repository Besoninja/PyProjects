{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664d0c64-e954-49d2-b1a3-72f3e2da6983",
   "metadata": {},
   "source": [
    "## Import Modules & CSV to be Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748bfae3-648b-4de7-85d5-8e5dd8be2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0e7f49-3fe4-484a-8ba1-7369e13f473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the CSV as a dataframe, called 'DF'\n",
    "DF = pd.read_csv('C:\\\\ITStuff\\\\DataSets\\\\2016_Olympics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9965844-39a3-4a45-982e-d367e3c92200",
   "metadata": {},
   "source": [
    "## Create and print function 'enhanced_info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810775eb-2f26-4b9c-9edf-ecb3d2a17a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex: 13688 entries, 0 to 13687\n",
      "Total Columns: 15\n",
      "\n",
      "   Column Name    Dtype  UniqueValues  NullCount %EmptyCells\n",
      "0           ID    int64         11179          0       0.00%\n",
      "1         Name   object         11174          0       0.00%\n",
      "2          Sex   object             2          0       0.00%\n",
      "3          Age    int64            48          0       0.00%\n",
      "4       Height  float64            78        176       1.29%\n",
      "5       Weight  float64           123        223       1.63%\n",
      "6         Team   object           228          0       0.00%\n",
      "7          NOC   object           207          0       0.00%\n",
      "8        Games   object             1          0       0.00%\n",
      "9         Year    int64             1          0       0.00%\n",
      "10      Season   object             1          0       0.00%\n",
      "11        City   object             1          0       0.00%\n",
      "12       Sport   object            34          0       0.00%\n",
      "13       Event   object           306          0       0.00%\n",
      "14       Medal   object             3      11665      85.22%\n",
      "\n",
      "Total missing data from the CSV: 5.88%\n",
      "\n",
      "Columns with Missing Values and Their Data Types:\n",
      "\tHeight - float64\n",
      "\tWeight - float64\n",
      "\tMedal - object\n"
     ]
    }
   ],
   "source": [
    "# Create and print an enhanced information table for our dataframe, called 'enhanced_info'\n",
    "# First, we print the length of the DataFrame to provide a basic overview.\n",
    "print(f\"RangeIndex: {DF.shape[0]} entries, 0 to {DF.shape[0] - 1}\")\n",
    "\n",
    "# Next, we print the total number of columns in the DataFrame.\n",
    "print(f\"Total Columns: {DF.shape[1]}\\n\")\n",
    "\n",
    "def enhanced_info(df):\n",
    "    \"\"\"\n",
    "    Generate and print a summary table that provides an enhanced view of the DataFrame.\n",
    "    \n",
    "    The summary includes the name, data type, number of unique values, count of null values,\n",
    "    and the percentage of empty cells for each column in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    The function also identifies and prints the total missing value proportion and a list of\n",
    "    columns with missing values including their data types.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store column information.\n",
    "    info_data = {\n",
    "        'Column Name': [],\n",
    "        'Dtype': [],\n",
    "        'UniqueValues': [],\n",
    "        'NullCount': [],\n",
    "        '%EmptyCells': [],\n",
    "    }\n",
    "\n",
    "    # A list to keep track of columns with missing values.\n",
    "    columns_with_missing = []\n",
    "    \n",
    "    # Iterate over each column in the DataFrame to gather detailed information.\n",
    "    for col in df.columns:\n",
    "        # Count the number of null values in the column.\n",
    "        null_count = df[col].isnull().sum()\n",
    "        \n",
    "        # Append the gathered information to the respective lists in the info_data dictionary.\n",
    "        info_data['Column Name'].append(col)\n",
    "        info_data['Dtype'].append(df[col].dtype)\n",
    "        info_data['UniqueValues'].append(df[col].nunique())\n",
    "        info_data['NullCount'].append(null_count)\n",
    "        \n",
    "        # Calculate the percentage of empty cells in the column.\n",
    "        empty_cells_prop = (null_count / df.shape[0]) * 100\n",
    "        info_data['%EmptyCells'].append(f'{empty_cells_prop:.2f}%')\n",
    "        \n",
    "        # If the column has missing values, add it to the columns_with_missing list.\n",
    "        if null_count > 0:\n",
    "            columns_with_missing.append((col, df[col].dtype))\n",
    "    \n",
    "    # Convert the info_data dictionary into a DataFrame for a tabular representation.\n",
    "    info_df = pd.DataFrame(info_data)\n",
    "    \n",
    "    # Print the generated DataFrame.\n",
    "    print(info_df.to_string(index=True))\n",
    "    \n",
    "    # Calculate and print the overall percentage of missing values in the DataFrame.\n",
    "    overall_missing_proportion = df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100\n",
    "    print(f'\\nTotal missing data from the CSV: {overall_missing_proportion:.2f}%')\n",
    "    \n",
    "    # If there are columns with missing values, print them along with their data types.\n",
    "    if columns_with_missing:\n",
    "        print(\"\\nColumns with Missing Values and Their Data Types:\")\n",
    "        for col, dtype in columns_with_missing:\n",
    "            print(f\"\\t{col} - {dtype}\")\n",
    "\n",
    "# Call the 'enhanced_info' function with the DataFrame 'DF'.\n",
    "enhanced_info(DF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72234903-9913-4bca-a74e-5a0ff8ea9ffb",
   "metadata": {},
   "source": [
    "## Create function 'columns_with_missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f470616-2b27-4968-8a1c-343bd5dc9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify columns with missing values and their data types, and returns them in a separate DataFrame\n",
    "def columns_with_missing(df):\n",
    "    \"\"\"\n",
    "    Identify and return a DataFrame containing columns with missing values and their data types.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame with columns 'Column Name' and 'Dtype' for columns with missing values.\n",
    "    \"\"\"\n",
    "    missing_info = [(col, df[col].dtype) for col in df.columns if df[col].isnull().sum() > 0]\n",
    "    columns_with_missing_df = pd.DataFrame(missing_info, columns=['Column Name', 'Dtype'])\n",
    "    return columns_with_missing_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9625fb58-86f4-405c-92cc-bf7209acc3eb",
   "metadata": {},
   "source": [
    "## Create function 'total_missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6ff6dd-d2c6-4eae-ac9c-ca76b161a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate total missing data percentage\n",
    "def total_missing(df):\n",
    "    \"\"\"\n",
    "    Calculate and return the total percentage of missing data in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The total missing data percentage, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    total_missing_data = df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100\n",
    "    return round(total_missing_data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553741c-3213-4991-a118-28f1c301322a",
   "metadata": {},
   "source": [
    "## Identify and Clean Columns with Mixed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a82600-1455-4b50-8a01-c0e97fc7b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column Name    Dtype  UniqueValues  NullCount %EmptyCells\n",
      "0           ID    int64         11179          0       0.00%\n",
      "1         Name   object         11174          0       0.00%\n",
      "2          Sex   object             2          0       0.00%\n",
      "3          Age    int64            48          0       0.00%\n",
      "4       Height  float64            78        176       1.29%\n",
      "5       Weight  float64           123        223       1.63%\n",
      "6         Team   object           228          0       0.00%\n",
      "7          NOC   object           207          0       0.00%\n",
      "8        Games   object             1          0       0.00%\n",
      "9         Year    int64             1          0       0.00%\n",
      "10      Season   object             1          0       0.00%\n",
      "11        City   object             1          0       0.00%\n",
      "12       Sport   object            34          0       0.00%\n",
      "13       Event   object           306          0       0.00%\n",
      "14       Medal   object             3      11665      85.22%\n",
      "\n",
      "Total missing data from the CSV: 5.88%\n",
      "\n",
      "Columns with Missing Values and Their Data Types:\n",
      "\tHeight - float64\n",
      "\tWeight - float64\n",
      "\tMedal - object\n"
     ]
    }
   ],
   "source": [
    "# The below code reassigns the data type of each column into one of three types (string, numeric or other) if more than 95% of values are of that type.\n",
    "# This function identifies the majority data type of each column\n",
    "def check_column_data_types(dataframe):\n",
    "    \"\"\"\n",
    "    Analyze each column in the DataFrame to determine its predominant data type \n",
    "    based on the content of the entries. A data type (string, numeric, or mixed) \n",
    "    is assigned to each column if more than 95% of its values belong to that type.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame whose columns are to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary mapping each column name to its identified predominant \n",
    "            data type ('numeric', 'string', or 'mixed').\n",
    "            \n",
    "    Note:\n",
    "    - Numeric data types are identified based on the ability to convert string \n",
    "      representations to floats or if the entry is already an integer or float.\n",
    "    - The 'mixed' data type is assigned if no single data type accounts for more \n",
    "      than 95% of the entries in the column.\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary to hold the data types\n",
    "    column_data_types = {}\n",
    "\n",
    "    # Iterate over each column in the dataframe\n",
    "    for column in dataframe.columns:\n",
    "        # Initialize counters for different data types\n",
    "        string_count = 0\n",
    "        numeric_count = 0\n",
    "        other_count = 0\n",
    "\n",
    "        # Check the data type of each entry in the column\n",
    "        for entry in dataframe[column]:\n",
    "            if isinstance(entry, str):\n",
    "                # Attempt to convert string to a float\n",
    "                try:\n",
    "                    float(entry)\n",
    "                    numeric_count += 1\n",
    "                except ValueError:\n",
    "                    string_count += 1\n",
    "            elif isinstance(entry, (int, float, np.number)):\n",
    "                numeric_count += 1\n",
    "            else:\n",
    "                other_count += 1\n",
    "\n",
    "        # Calculate the ratio of each data type\n",
    "        total_entries = len(dataframe[column])\n",
    "        numeric_ratio = numeric_count / total_entries\n",
    "        string_ratio = string_count / total_entries\n",
    "\n",
    "        # Set a threshold for determining the predominant data type\n",
    "        threshold = 0.95\n",
    "\n",
    "        # Assign the predominant data type based on the calculated ratios\n",
    "        if numeric_ratio > threshold:\n",
    "            column_data_type = 'numeric'\n",
    "        elif string_ratio > threshold:\n",
    "            column_data_type = 'string'\n",
    "        else:\n",
    "            column_data_type = 'mixed'\n",
    "\n",
    "        column_data_types[column] = column_data_type\n",
    "\n",
    "    return column_data_types\n",
    "\n",
    "# Reassign column data types based on the identified majority data type, and change the values within those columns\n",
    "def reassign_column_dtypes_with_na(dataframe, column_data_types):\n",
    "    \"\"\"\n",
    "    Reassign the data types of DataFrame columns based on a given mapping of \n",
    "    columns to their predominant data types. Columns identified as 'numeric' \n",
    "    are converted to numeric types, with non-numeric entries set to NaN. Columns \n",
    "    identified as 'string' have non-string entries replaced with 'N/A'. Columns \n",
    "    marked as 'mixed' are left unchanged.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame whose columns are to be reassigned.\n",
    "    - column_data_types (dict): A dictionary mapping column names to their \n",
    "                                predominant data type ('numeric', 'string', \n",
    "                                or 'mixed') as identified by check_column_data_types.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with modified column data types according to \n",
    "                    the provided mapping.\n",
    "\n",
    "    Note:\n",
    "    - This operation modifies the input DataFrame in-place, potentially altering \n",
    "      data entries to conform to the identified predominant data type.\n",
    "    \"\"\"\n",
    "    for column, dtype in column_data_types.items():\n",
    "        if dtype == 'numeric':\n",
    "            # Convert column to numeric, making non-numeric entries NaN\n",
    "            dataframe[column] = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "        elif dtype == 'string':\n",
    "            # Convert all non-string entries to 'N/A'\n",
    "            dataframe[column] = dataframe[column].apply(lambda x: x if isinstance(x, str) else 'N/A')\n",
    "        elif dtype == 'mixed':\n",
    "            # Leave mixed type columns as is for now\n",
    "            pass\n",
    "    return dataframe\n",
    "\n",
    "# Analyze the data types for each column in the DataFrame\n",
    "column_types = check_column_data_types(DF)\n",
    "\n",
    "# Reassign the data types based on the predominant data type of each column\n",
    "DF = reassign_column_dtypes_with_na(DF, column_types)\n",
    "\n",
    "# You can now proceed with further data cleaning or analysis with the DataFrame\n",
    "enhanced_info(DF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421f949-b026-47ca-9aeb-8c69d13799fd",
   "metadata": {},
   "source": [
    "## Identify and reassign Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b776736-968d-4d5c-96ad-ab57b1c0fcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column Name     Dtype  UniqueValues  NullCount %EmptyCells\n",
      "0           ID     int64         11179          0       0.00%\n",
      "1         Name    object         11174          0       0.00%\n",
      "2          Sex  category             2          0       0.00%\n",
      "3          Age     int64            48          0       0.00%\n",
      "4       Height   float64            78        176       1.29%\n",
      "5       Weight   float64           123        223       1.63%\n",
      "6         Team  category           228          0       0.00%\n",
      "7          NOC  category           207          0       0.00%\n",
      "8        Games  category             1          0       0.00%\n",
      "9         Year     int64             1          0       0.00%\n",
      "10      Season  category             1          0       0.00%\n",
      "11        City  category             1          0       0.00%\n",
      "12       Sport  category            34          0       0.00%\n",
      "13       Event  category           306          0       0.00%\n",
      "14       Medal  category             3      11665      85.22%\n",
      "\n",
      "Total missing data from the CSV: 5.88%\n",
      "\n",
      "Columns with Missing Values and Their Data Types:\n",
      "\tHeight - float64\n",
      "\tWeight - float64\n",
      "\tMedal - category\n"
     ]
    }
   ],
   "source": [
    "# PID Categorical Columns\n",
    "#Determine if a column should be treated as categorical. \n",
    "#If the number of unique values is less than 10% of the length then col is reassigned as 'categorical' dtype.\n",
    "def is_categorical(column, threshold=0.1):\n",
    "    \"\"\"\n",
    "    :column: pandas Series data (a column from our DataFrame)\n",
    "    :threshold: float, the threshold ratio of unique values to total values for categorization\n",
    "    :return: bool, True if <10%, False otherwise\n",
    "    \"\"\"\n",
    "    # Calculate the ratio of unique values to the length of the column\n",
    "    unique_ratio = column.nunique() / len(column)\n",
    "    # If the ratio is less than the threshold, consider it as categorical\n",
    "    return unique_ratio < threshold\n",
    "    \n",
    "#Reassign columns to 'category' where applicable.\n",
    "def reassign_categorical_data_types(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:  # Loop through 'object' type columns\n",
    "        if is_categorical(df[col]):  # Check if the column is categorical\n",
    "            df[col] = pd.Categorical(df[col])  # Convert to categorical type\n",
    "    return df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "DF = reassign_categorical_data_types(DF)\n",
    "\n",
    "# Optionally, print the DataFrame's info to verify the changes\n",
    "enhanced_info(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328249d1-ae7d-4417-9f4f-84a088b0ff90",
   "metadata": {},
   "source": [
    "# Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016e7f0-dec5-416e-b63e-507aa29e50ab",
   "metadata": {},
   "source": [
    "## Select columns by DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb56c4b3-c70b-483b-919c-605a4f5964a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the type of columns you want to handle:\n",
      "Press 1 for Numerical\n",
      "Press 2 for Non-numerical\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1/2):  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m user_choice \u001b[38;5;241m=\u001b[39m get_user_choice()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Step 2: Filter columns based on the user's choice\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m filtered_columns \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_columns_by_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_with_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_choice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Output the filtered columns to verify\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected columns for imputation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m, in \u001b[0;36mfilter_columns_by_type\u001b[1;34m(columns_with_missing, choice)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Filter for non-numerical (categorical) columns\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     data_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimedelta[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Common non-numerical data types in pandas\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m filtered_columns \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns_with_missing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_types\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered_columns\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "def get_user_choice():\r\n",
    "    \"\"\"\r\n",
    "    Prompt the user to choose between numerical and categorical column handling.\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - choice: An integer representing the user's choice (1 for numerical, 2 for non-numerical).\r\n",
    "    \"\"\"\r\n",
    "    print(\"Please select the type of columns you want to handle:\")\r\n",
    "    print(\"Press 1 for Numerical\")\r\n",
    "    print(\"Press 2 for Non-numerical\")\r\n",
    "    choice = input(\"Enter your choice (1/2): \")\r\n",
    "    while choice not in ['1', '2']:\r\n",
    "        print(\"Invalid input. Please enter 1 for Numerical or 2 for Non-numerical.\")\r\n",
    "        choice = input(\"Enter your choice (1/2): \")\r\n",
    "    return int(choice)\r\n",
    "\r\n",
    "def filter_columns_by_type(columns_with_missing, choice):\r\n",
    "    \"\"\"\r\n",
    "    Filter the list of columns with missing values by the user's selected data type.\r\n",
    "    \r\n",
    "    Parameters:\r\n",
    "    - columns_with_missing: A DataFrame containing the Column Name and Dtype of columns with missing values.\r\n",
    "    - choice: An integer representing the user's choice (1 for numerical, 2 for non-numerical).\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "    - filtered_columns: A list of column names filtered by the selected data type.\r\n",
    "    \"\"\"\r\n",
    "    if choice == 1:\r\n",
    "        # Filter for numerical columns\r\n",
    "        data_types = ['int64', 'float64']  # Common numerical data types in pandas\r\n",
    "    else:\r\n",
    "        # Filter for non-numerical (categorical) columns\r\n",
    "        data_types = ['object', 'category', 'bool', 'datetime64[ns]', 'timedelta[ns]']  # Common non-numerical data types in pandas\r\n",
    "    \r\n",
    "    filtered_columns = [col for col, dtype in columns_with_missing if dtype in data_types]\r\n",
    "    return filtered_columns\r\n",
    "\r\n",
    "# Step 1: Get the user's choice\r\n",
    "user_choice = get_user_choice()\r\n",
    "\r\n",
    "# Step 2: Filter columns based on the user's choice\r\n",
    "filtered_columns = filter_columns_by_type(columns_with_missing, user_choice)\r\n",
    "\r\n",
    "# Output the filtered columns to verify\r\n",
    "print(\"Selected columns for imputation:\")\r\n",
    "for col in filtered_columns:\r\n",
    "    print(col)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
