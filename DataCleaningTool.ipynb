{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4029ae15-b339-47fe-a7bf-c78a3b3e0e19",
   "metadata": {},
   "source": [
    "#Data Cleaning Tool\n",
    "This data cleaning tool is built to clean and sort messy data. \n",
    "The tool is modular in design, i.e. any or all parts of the tool can be run on your data. It has many different functions focusing of a particular aspect of the data cleaning process. \n",
    "\n",
    "The list of things to do for this tool include:\n",
    "\n",
    "\t1) Import a messy CSV as a DataFrame called \"DF\"\n",
    "\t1a) Create an 'enhanced_info' table - gives a better view of the dataset and it's missingness\n",
    "    2) Handling columns with mixed data and Data Type Conversion \n",
    "\t3) Handling Missing Values Let the user decide what they want to do with the missing values \n",
    "\t4) Normalisation and scaling \n",
    "\t5) Filtering and Selecting Data \n",
    "\t6) Dealing with Duplicates \n",
    "\t7) Handling Outliers \n",
    "\t8) Data Transformation \n",
    "\t9) Feature Engineering \n",
    "\t10) Error Checking and Reporting\n",
    "\n",
    "Given the modular nature of this tool this jpynb will be divided into one code block per function :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "614a067d-1438-41ad-a137-48f1e77031a8",
   "metadata": {},
   "source": [
    "## Import Modules & CSV to be Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301b9656-f22a-4021-bde0-22f69e7f8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Import the CSV as a dataframe, called 'DF'\n",
    "DF = pd.read_csv('E:\\\\Ben\\\\Data Sets\\\\2016_Olympics1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a3228-5469-4f00-ba2e-0d39cdd668fb",
   "metadata": {},
   "source": [
    "## Create an 'enhanced information table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995ec1ab-5870-4b6a-b34e-49d8a2af52c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex: 13688 entries, 0 to 13687\n",
      "Total Columns: 15\n",
      "\n",
      "ColumnName DataType  UniqueValues  NullCount % EmptyCells\n",
      "        ID    int64         11179          0        0.00%\n",
      "      Name   object         11174          0        0.00%\n",
      "       Sex   object             2          0        0.00%\n",
      "       Age    int64            48          0        0.00%\n",
      "    Height  float64            78        176        1.29%\n",
      "    Weight  float64           123        223        1.63%\n",
      "      Team   object           249          0        0.00%\n",
      "       NOC   object           207          0        0.00%\n",
      "     Games   object             1          0        0.00%\n",
      "      Year   object             4          0        0.00%\n",
      "    Season   object             1          0        0.00%\n",
      "      City   object             1          0        0.00%\n",
      "     Sport   object            34          0        0.00%\n",
      "     Event   object           306          0        0.00%\n",
      "     Medal   object             3      11665       85.22%\n",
      "\n",
      "Total Missing Value Proportion: 5.88%\n",
      "\n",
      "Columns with Missing Values and Their Data Types:\n",
      "Height: float64\n",
      "Weight: float64\n",
      "Medal: object\n"
     ]
    }
   ],
   "source": [
    "## Create and print function 'enhanced_info'\n",
    "# Create and print an enhanced information table for our dataframe, called 'enhanced_info'\n",
    "# First, we print the length of the DataFrame to provide a basic overview.\n",
    "print(f\"RangeIndex: {DF.shape[0]} entries, 0 to {DF.shape[0] - 1}\")\n",
    "\n",
    "# Next, we print the total number of columns in the DataFrame.\n",
    "print(f\"Total Columns: {DF.shape[1]}\\n\")\n",
    "\n",
    "def enhanced_info(df):\n",
    "    \"\"\"\n",
    "    Generate and print a summary table that provides an enhanced view of the DataFrame.\n",
    "    \n",
    "    The summary includes the name, data type, number of unique values, count of null values,\n",
    "    and the percentage of empty cells for each column in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    The function also identifies and prints the total missing value proportion and a list of\n",
    "    columns with missing values including their data types.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store column information.\n",
    "    info_data = {\n",
    "        'ColumnName': [],\n",
    "        'DataType': [], \n",
    "        'UniqueValues': [],\n",
    "        'NullCount': [],\n",
    "        '% EmptyCells': [],\n",
    "    }\n",
    "\n",
    "    # A list to keep track of columns with missing values.\n",
    "    columns_with_missing = []\n",
    "    \n",
    "    # Iterate over each column in the DataFrame to gather detailed information.\n",
    "    for col in df.columns:\n",
    "        # Count the number of null values in the column.\n",
    "        null_count = df[col].isnull().sum()\n",
    "        \n",
    "        # Append the gathered information to the respective lists in the info_data dictionary.\n",
    "        info_data['ColumnName'].append(col)\n",
    "        info_data['DataType'].append(df[col].dtype.name)\n",
    "        info_data['UniqueValues'].append(df[col].nunique())\n",
    "        info_data['NullCount'].append(null_count)\n",
    "        \n",
    "        # Calculate the percentage of empty cells in the column.\n",
    "        empty_cells_prop = (null_count / df.shape[0]) * 100\n",
    "        info_data['% EmptyCells'].append(f'{empty_cells_prop:.2f}%')\n",
    "        \n",
    "        # If the column has missing values, add it to the columns_with_missing list.\n",
    "        if null_count > 0:\n",
    "            columns_with_missing.append((col, df[col].dtype))\n",
    "\n",
    "    # Convert info_data dictionary into a DataFrame for tabular representation.\n",
    "    info_df = pd.DataFrame(info_data)\n",
    "\n",
    "    print(info_df.to_string(index=False))\n",
    "\n",
    "    overall_missing_proportion = df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100\n",
    "    print(f\"\\nTotal Missing Value Proportion: {overall_missing_proportion:.2f}%\")\n",
    "\n",
    "    if columns_with_missing:\n",
    "        print(\"\\nColumns with Missing Values and Their Data Types:\")\n",
    "        for col, dtype in columns_with_missing:\n",
    "            print(f\"{col}: {dtype}\")\n",
    "            \n",
    "# Call the 'enhanced_info' function with the DataFrame 'DF'.\n",
    "enhanced_info(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf9956f-be2f-430c-96f5-66165e45ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 15 entries, ID to Medal\n",
      "Series name: None\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "15 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 796.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "DF.dtypes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1034b-a1a5-4832-8cba-c2170c8c0759",
   "metadata": {},
   "source": [
    "## Create function 'columns_with_missing()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7782a651-8497-46ef-83c4-2000668bacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify columns with missing values and their data types, and returns them in a separate DataFrame\n",
    "def columns_with_missing(df):\n",
    "    \"\"\"\n",
    "    Identify and return a DataFrame containing columns with missing values and their data types.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame with columns 'Column Name' and 'Dtype' for columns with missing values.\n",
    "    \"\"\"\n",
    "    missing_info = [(col, df[col].dtype.name) for col in df.columns if df[col].isnull().sum() > 0]\n",
    "    columns_with_missing_df = pd.DataFrame(missing_info, columns=['ColumnName', 'DataType'])\n",
    "    return columns_with_missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e5ee6-061e-4b12-b9ef-4450e3f0cdcb",
   "metadata": {},
   "source": [
    "## Create function 'total_missing()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d399ed-2f4a-4790-abf8-d7b726d9dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate total missing data percentage\n",
    "def total_missing(df):\n",
    "    \"\"\"\n",
    "    Calculate and return the total percentage of missing data in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The total missing data percentage, rounded to two decimal places.\n",
    "    \"\"\"\n",
    "    total_missing_data = df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100\n",
    "    return round(total_missing_data, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c61930-88e4-4a64-b346-037974ce3833",
   "metadata": {},
   "source": [
    "## Identify and Clean Columns with Mixed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cdc9b2-1429-42e1-a4a2-fed30bad0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName DataType  UniqueValues  NullCount % EmptyCells\n",
      "        ID    int64         11179          0        0.00%\n",
      "      Name   object         11174          0        0.00%\n",
      "       Sex   object             2          0        0.00%\n",
      "       Age    int64            48          0        0.00%\n",
      "    Height  float64            78        176        1.29%\n",
      "    Weight  float64           123        223        1.63%\n",
      "      Team   object           249          0        0.00%\n",
      "       NOC   object           207          0        0.00%\n",
      "     Games   object             1          0        0.00%\n",
      "      Year  float64             1          3        0.02%\n",
      "    Season   object             1          0        0.00%\n",
      "      City   object             1          0        0.00%\n",
      "     Sport   object            34          0        0.00%\n",
      "     Event   object           306          0        0.00%\n",
      "     Medal   object             3      11665       85.22%\n",
      "\n",
      "Total Missing Value Proportion: 5.88%\n",
      "\n",
      "Columns with Missing Values and Their Data Types:\n",
      "Height: float64\n",
      "Weight: float64\n",
      "Year: float64\n",
      "Medal: object\n"
     ]
    }
   ],
   "source": [
    "# The below code reassigns the data type of each column into one of three types (string, numeric or other) if more than 95% of values are of that type.\n",
    "# This function identifies the majority data type of each column\n",
    "def check_column_data_types(dataframe):\n",
    "    \"\"\"\n",
    "    Analyze each column in the DataFrame to determine its predominant data type \n",
    "    based on the content of the entries. A data type (string, numeric, or mixed) \n",
    "    is assigned to each column if more than 95% of its values belong to that type.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame whose columns are to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary mapping each column name to its identified predominant \n",
    "            data type ('numeric', 'string', or 'mixed').\n",
    "            \n",
    "    Note:\n",
    "    - Numeric data types are identified based on the ability to convert string \n",
    "      representations to floats or if the entry is already an integer or float.\n",
    "    - The 'mixed' data type is assigned if no single data type accounts for more \n",
    "      than 95% of the entries in the column.\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary to hold the data types\n",
    "    column_data_types = {}\n",
    "\n",
    "    # Iterate over each column in the dataframe\n",
    "    for column in dataframe.columns:\n",
    "        # Initialize counters for different data types\n",
    "        string_count = 0\n",
    "        numeric_count = 0\n",
    "        other_count = 0\n",
    "\n",
    "        # Check the data type of each entry in the column\n",
    "        for entry in dataframe[column]:\n",
    "            if isinstance(entry, str):\n",
    "                # Attempt to convert string to a float\n",
    "                try:\n",
    "                    float(entry)\n",
    "                    numeric_count += 1\n",
    "                except ValueError:\n",
    "                    string_count += 1\n",
    "            elif isinstance(entry, (int, float, np.number)):\n",
    "                numeric_count += 1\n",
    "            else:\n",
    "                other_count += 1\n",
    "\n",
    "        # Calculate the ratio of each data type\n",
    "        total_entries = len(dataframe[column])\n",
    "        numeric_ratio = numeric_count / total_entries\n",
    "        string_ratio = string_count / total_entries\n",
    "\n",
    "        # Set a threshold for determining the predominant data type\n",
    "        threshold = 0.95\n",
    "\n",
    "        # Assign the predominant data type based on the calculated ratios\n",
    "        if numeric_ratio > threshold:\n",
    "            column_data_type = 'numeric'\n",
    "        elif string_ratio > threshold:\n",
    "            column_data_type = 'string'\n",
    "        else:\n",
    "            column_data_type = 'mixed'\n",
    "\n",
    "        column_data_types[column] = column_data_type\n",
    "\n",
    "    return column_data_types\n",
    "\n",
    "# Reassign column data types based on the identified majority data type, and change the values within those columns\n",
    "def reassign_column_dtypes_with_na(dataframe, column_data_types):\n",
    "    \"\"\"\n",
    "    Reassign the data types of DataFrame columns based on a given mapping of \n",
    "    columns to their predominant data types. Columns identified as 'numeric' \n",
    "    are converted to numeric types, with non-numeric entries set to NaN. Columns \n",
    "    identified as 'string' have non-string entries replaced with 'N/A'. Columns \n",
    "    marked as 'mixed' are left unchanged.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame whose columns are to be reassigned.\n",
    "    - column_data_types (dict): A dictionary mapping column names to their \n",
    "                                predominant data type ('numeric', 'string', \n",
    "                                or 'mixed') as identified by check_column_data_types.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with modified column data types according to \n",
    "                    the provided mapping.\n",
    "\n",
    "    Note:\n",
    "    - This operation modifies the input DataFrame in-place, potentially altering \n",
    "      data entries to conform to the identified predominant data type.\n",
    "    \"\"\"\n",
    "    for column, dtype in column_data_types.items():\n",
    "        if dtype == 'numeric':\n",
    "            # Convert column to numeric, making non-numeric entries NaN\n",
    "            dataframe[column] = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "        elif dtype == 'string':\n",
    "            # Convert all non-string entries to 'N/A'\n",
    "            dataframe[column] = dataframe[column].apply(lambda x: x if isinstance(x, str) else 'N/A')\n",
    "        elif dtype == 'mixed':\n",
    "            # Leave mixed type columns as is for now\n",
    "            pass\n",
    "    return dataframe\n",
    "\n",
    "# Analyze the data types for each column in the DataFrame\n",
    "column_types = check_column_data_types(DF)\n",
    "\n",
    "# Reassign the data types based on the predominant data type of each column\n",
    "DF = reassign_column_dtypes_with_na(DF, column_types)\n",
    "\n",
    "# Print the Data Frame with the newly refined columns\n",
    "enhanced_info(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721cd5b2-d1c3-4fea-b7be-d5e8dc921a41",
   "metadata": {},
   "source": [
    "## Identify and reassign Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5462bcff-289a-4b63-a9c0-f36c9c37bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName DataType  UniqueValues  NullCount % EmptyCells\n",
      "        ID    int64         11179          0        0.00%\n",
      "      Name   object         11174          0        0.00%\n",
      "       Sex category             2          0        0.00%\n",
      "       Age    int64            48          0        0.00%\n",
      "    Height  float64            78        176        1.29%\n",
      "    Weight  float64           123        223        1.63%\n",
      "      Team category           249          0        0.00%\n",
      "       NOC category           207          0        0.00%\n",
      "     Games category             1          0        0.00%\n",
      "      Year  float64             1          3        0.02%\n",
      "    Season category             1          0        0.00%\n",
      "      City category             1          0        0.00%\n",
      "     Sport category            34          0        0.00%\n",
      "     Event category           306          0        0.00%\n",
      "     Medal category             3      11665       85.22%\n",
      "\n",
      "Total Missing Value Proportion: 5.88%\n",
      "\n",
      "Columns with Missing Values and Their Data Types:\n",
      "Height: float64\n",
      "Weight: float64\n",
      "Year: float64\n",
      "Medal: category\n"
     ]
    }
   ],
   "source": [
    "# PID Categorical Columns\n",
    "#Determine if a column should be treated as categorical. \n",
    "#If the number of unique values is less than 10% of the length then col is reassigned as 'categorical' dtype.\n",
    "def is_categorical(column, threshold=0.1):\n",
    "    \"\"\"\n",
    "    :column: pandas Series data (a column from our DataFrame)\n",
    "    :threshold: float, the threshold ratio of unique values to total values for categorization\n",
    "    :return: bool, True if <10%, False otherwise\n",
    "    \"\"\"\n",
    "    # Calculate the ratio of unique values to the length of the column\n",
    "    unique_ratio = column.nunique() / len(column)\n",
    "    # If the ratio is less than the threshold, consider it as categorical\n",
    "    return unique_ratio < threshold\n",
    "    \n",
    "#Reassign columns to 'category' where applicable.\n",
    "def reassign_categorical_data_types(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:  # Loop through 'object' type columns\n",
    "        if is_categorical(df[col]):  # Check if the column is categorical\n",
    "            df[col] = pd.Categorical(df[col])  # Convert to categorical type\n",
    "    return df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "DF = reassign_categorical_data_types(DF)\n",
    "\n",
    "# Optionally, print the DataFrame's info to verify the changes\n",
    "enhanced_info(DF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23b36e-2476-4c40-8921-cbf96dba7ae2",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 12px; background-color: #ccc;\">\n",
    "<h1> <center> · • ═══════════╡ Module 1 ╞═══════════ • · </center></h1>\n",
    "<h1> <center>· •• ═══════╡ Handling Missing Values ╞═══════ •• · </center></h1>\n",
    "<hr style=\"border: none; height: 12px; background-color: #ccc;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1b1ed-0e04-4284-8311-5a02c823790e",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "### Select columns by DataType to impute missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e87999-3bd7-4783-94da-fe46aaa73e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the type of columns you want to handle:\n",
      "Press 1 for Numerical\n",
      "Press 2 for Non-numerical\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1/2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns for handling missing values:\n",
      "Medal\n"
     ]
    }
   ],
   "source": [
    "def get_user_choice():\n",
    "    print(\"Please select the type of columns you want to handle:\")\n",
    "    print(\"Press 1 for Numerical\")\n",
    "    print(\"Press 2 for Non-numerical\")\n",
    "    choice = input(\"Enter your choice (1/2): \")\n",
    "    while choice not in ['1', '2']:\n",
    "        print(\"Invalid input. Please enter 1 for Numerical or 2 for Non-numerical.\")\n",
    "        choice = input(\"Enter your choice (1/2): \")\n",
    "    return int(choice)\n",
    "\n",
    "def filter_columns_by_type(df, choice):\n",
    "    # First, get all columns with missing values\n",
    "    cols_with_missing = df.columns[df.isnull().any()].tolist()\n",
    "    # Then filter these columns based on the data type\n",
    "    if choice == 1:\n",
    "        # Select numerical columns with missing values\n",
    "        filtered_columns = df[cols_with_missing].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    else:\n",
    "        # Select non-numerical columns with missing values\n",
    "        filtered_columns = df[cols_with_missing].select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "    return filtered_columns\n",
    "\n",
    "# Usage:\n",
    "# Step 1: Get the user's choice\n",
    "user_choice = get_user_choice()\n",
    "\n",
    "# Step 2: Filter columns based on the user's choice\n",
    "filtered_columns = filter_columns_by_type(DF, user_choice)\n",
    "\n",
    "# Output the filtered columns to verify\n",
    "print(\"Selected columns for handling missing values:\")\n",
    "for col in filtered_columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672a828c-148b-4b6b-962d-9dc1f07c01e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13683</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13684</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13685</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13686</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13688 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Medal\n",
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "...     ...\n",
       "13683   NaN\n",
       "13684   NaN\n",
       "13685   NaN\n",
       "13686   NaN\n",
       "13687   NaN\n",
       "\n",
       "[13688 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[filtered_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1e700-d649-448c-9e3c-dee94cefc765",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365771b-7dd7-4081-bac9-93cf0e35ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
